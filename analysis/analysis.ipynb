{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir('../')\n",
    "from data_processing.paths import raw_folder_name, mask_folder_name, blur_folder_name, grey_folder_name\n",
    "\n",
    "raw_images_path = Path(raw_folder_name)\n",
    "mask_images_path = Path(mask_folder_name)\n",
    "blurred_images_path = Path(blur_folder_name)\n",
    "grey_images_path = Path(grey_folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from models.data_loader import get_dataloader\n",
    "\n",
    "dataset_name = 'ffhq_raw'\n",
    "batch_size = 4\n",
    "\n",
    "# Assuming loader is your DataLoader instance\n",
    "loader = get_dataloader(dataset_name, batch_size, shuffle=False, resolution=8, alpha=1)\n",
    "\n",
    "# Get a batch of images\n",
    "images = next(iter(loader))\n",
    "\n",
    "# Select the first image from the batch\n",
    "normalized_image = images[0]\n",
    "\n",
    "# Denormalize transform\n",
    "inv_normalize = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[2.0, 2.0, 2.0]),\n",
    "    transforms.Normalize(mean=[-0.5, -0.5, -0.5], std=[1.0, 1.0, 1.0])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply denormalization\n",
    "denormalized_image = inv_normalize(normalized_image)\n",
    "\n",
    "\n",
    "# Display the images for visual comparison\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(normalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Normalized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denormalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from models.data_loader import get_dataloader\n",
    "\n",
    "dataset_name = 'ffhq_raw'\n",
    "batch_size = 4\n",
    "\n",
    "# Assuming loader is your DataLoader instance\n",
    "loader = get_dataloader(dataset_name, batch_size, shuffle=False, resolution=16, alpha=0.00001)\n",
    "\n",
    "# Get a batch of images\n",
    "images = next(iter(loader))\n",
    "\n",
    "# Select the first image from the batch\n",
    "normalized_image = images[0]\n",
    "\n",
    "# Denormalize transform\n",
    "inv_normalize = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[2.0, 2.0, 2.0]),\n",
    "    transforms.Normalize(mean=[-0.5, -0.5, -0.5], std=[1.0, 1.0, 1.0])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply denormalization\n",
    "denormalized_image = inv_normalize(normalized_image)\n",
    "\n",
    "\n",
    "# Display the images for visual comparison\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(normalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Normalized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denormalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from models.data_loader import get_dataloader\n",
    "\n",
    "dataset_name = 'ffhq_raw'\n",
    "batch_size = 4\n",
    "\n",
    "# Assuming loader is your DataLoader instance\n",
    "loader = get_dataloader(dataset_name, batch_size, shuffle=False, resolution=16, alpha=0.5)\n",
    "\n",
    "# Get a batch of images\n",
    "images = next(iter(loader))\n",
    "\n",
    "# Select the first image from the batch\n",
    "normalized_image = images[0]\n",
    "\n",
    "# Denormalize transform\n",
    "inv_normalize = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[2.0, 2.0, 2.0]),\n",
    "    transforms.Normalize(mean=[-0.5, -0.5, -0.5], std=[1.0, 1.0, 1.0])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply denormalization\n",
    "denormalized_image = inv_normalize(normalized_image)\n",
    "\n",
    "\n",
    "# Display the images for visual comparison\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(normalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Normalized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denormalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from models.data_loader import get_dataloader\n",
    "\n",
    "dataset_name = 'ffhq_raw'\n",
    "batch_size = 4\n",
    "\n",
    "# Assuming loader is your DataLoader instance\n",
    "loader = get_dataloader(dataset_name, batch_size, shuffle=False, resolution=16, alpha=1)\n",
    "\n",
    "# Get a batch of images\n",
    "images = next(iter(loader))\n",
    "\n",
    "# Select the first image from the batch\n",
    "normalized_image = images[0]\n",
    "\n",
    "# Denormalize transform\n",
    "inv_normalize = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[2.0, 2.0, 2.0]),\n",
    "    transforms.Normalize(mean=[-0.5, -0.5, -0.5], std=[1.0, 1.0, 1.0])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply denormalization\n",
    "denormalized_image = inv_normalize(normalized_image)\n",
    "\n",
    "\n",
    "# Display the images for visual comparison\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(normalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Normalized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denormalized_image.permute(1, 2, 0))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from data_processing.paths import raw_folder_name, mask_folder_name, blur_folder_name, grey_folder_name\n",
    "\n",
    "def display_variants(image_name):\n",
    "    # Construct paths to the image variants\n",
    "    raw_path = Path(raw_folder_name) / f\"{image_name}.png\"\n",
    "    mask_path = Path(mask_folder_name) / f\"{image_name}.png\"\n",
    "    blur_path = Path(blur_folder_name) / f\"{image_name}.png\"\n",
    "    grey_path = Path(grey_folder_name) / f\"{image_name}.png\"\n",
    "    \n",
    "    # Load images\n",
    "    raw_img = Image.open(raw_path)\n",
    "    mask_img = Image.open(mask_path)\n",
    "    blur_img = Image.open(blur_path)\n",
    "    grey_img = Image.open(grey_path)\n",
    "    \n",
    "    # Set up the matplotlib figure and axes\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))  # Adjust the size as needed\n",
    "    \n",
    "    # Display images\n",
    "    axs[0].imshow(raw_img)\n",
    "    axs[0].set_title('Raw')\n",
    "    axs[0].axis('off')  # Hide axis\n",
    "    \n",
    "    axs[1].imshow(mask_img, cmap='gray')\n",
    "    axs[1].set_title('Mask')\n",
    "    axs[1].axis('off')  # Hide axis\n",
    "    \n",
    "    axs[2].imshow(blur_img)\n",
    "    axs[2].set_title('Blurred')\n",
    "    axs[2].axis('off')  # Hide axis\n",
    "    \n",
    "    axs[3].imshow(grey_img)\n",
    "    axs[3].set_title('Grey')\n",
    "    axs[3].axis('off')  # Hide axis\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "display_variants('00001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_variants('00913')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_variants('00018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from models.data_loader import FFHQDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function to compute mean and standard deviation\n",
    "def compute_dataset_mean_std(loader):\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    # Loop through all the images in the DataLoader\n",
    "    for images in tqdm(loader):\n",
    "        for image in images:\n",
    "            # Update mean and std\n",
    "            mean += image.mean(axis=(1, 2)).numpy()\n",
    "            std += image.std(axis=(1, 2)).numpy()\n",
    "    mean /= len(loader.dataset)\n",
    "    std /= len(loader.dataset)\n",
    "    return mean, std\n",
    "\n",
    "# Define transformations without normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the dataset without any normalization\n",
    "root_dir = 'data_processing/ffhq_raw'\n",
    "dataset = FFHQDataset(root_dir=root_dir, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=4, shuffle=False)\n",
    "\n",
    "# Compute the mean and std\n",
    "mean, std = compute_dataset_mean_std(loader)\n",
    "print(f\"Computed Mean: {mean}\")\n",
    "print(f\"Computed Std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data_processing/ffhq_grey'\n",
    "dataset = FFHQDataset(root_dir=root_dir, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=4, shuffle=False)\n",
    "\n",
    "# Compute the mean and std\n",
    "mean, std = compute_dataset_mean_std(loader)\n",
    "print(f\"Computed Mean: {mean}\")\n",
    "print(f\"Computed Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data_processing/ffhq_blur'\n",
    "dataset = FFHQDataset(root_dir=root_dir, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=4, shuffle=False)\n",
    "\n",
    "# Compute the mean and std\n",
    "mean, std = compute_dataset_mean_std(loader)\n",
    "print(f\"Computed Mean: {mean}\")\n",
    "print(f\"Computed Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml-vae-l9SVH2J7-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
